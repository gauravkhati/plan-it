# Plan-It ğŸ“‹

**Plan-It** is a sophisticated conversational planning agent that helps users organize thoughts, create structured plans, and refine them through natural dialogue.

Built with a **FastAPI** backend powering a **LangGraph** agent (using **Gemini 2.0 Flash**), and a modern, premium **React** frontend.

## âœ¨ Features

- **Conversational Intelligence** â€” Powered by Gemini 2.0 and LangGraph for context-aware, multi-turn planning.
- **Structured Planning** â€”  Automatically generates organized plans with steps, status tracking, and descriptions.
- **Smart Context Management** â€” Handles long conversations with intelligent context compression and token management.
- **Secure Authentication** â€” Complete email/password authentication system with JWT sessions.
- **Persistent Storage** â€” Saves all plans, versions, and chat history using MongoDB (or in-memory for testing).
- **Premium UI/UX** â€” A polished "Vibrant Pro" React interface with:
  - Real-time chat with optimistic updates
  - Split-view dashboard (Chat + Plan)
  - Plan version history
  - Responsive design with smooth animations
  - Modern "Vibrant Pro" theme (Electric Indigo/Violet)

## ğŸ—ï¸ Project Structure

```
Plan-It/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agent.py           # LangGraph agent definition & logic
â”‚   â”œâ”€â”€ auth.py            # JWT auth, user management, password hashing
â”‚   â”œâ”€â”€ context_manager.py # Token counting & context compression
â”‚   â”œâ”€â”€ models.py          # Pydantic data models
â”‚   â”œâ”€â”€ server.py          # FastAPI application & endpoints
â”‚   â””â”€â”€ session_store.py   # MongoDB & In-Memory storage backends
â”œâ”€â”€ frontend-react/        # Modern React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components (ChatPanel, PlanPanel, etc.)
â”‚   â”‚   â”œâ”€â”€ services/      # API client
â”‚   â”‚   â”œâ”€â”€ App.jsx        # Main application logic
â”‚   â”‚   â””â”€â”€ index.css      # Premium "Vibrant Pro" styling
â”‚   â””â”€â”€ vite.config.js     # Vite configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Backend Setup

1. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Environment Configuration**
   Copy `.env.example` to `.env` and configure your keys:
   ```bash
   cp .env.example .env
   ```
   *Required:* `GOOGLE_API_KEY` (Get from AI Studio)
   *Optional:* `MONGODB_URI` (Defaults to in-memory storage if omitted)

3. **Start the Server**
   ```bash
   uvicorn backend.server:app --reload --port 8000
   ```

### Frontend Setup

1. **Navigate to frontend directory**
   ```bash
   cd frontend-react
   ```

2. **Install Node dependencies**
   ```bash
   npm install
   ```

3. **Start the Development Server**
   ```bash
   npm run dev
   ```
   Open [http://localhost:5173](http://localhost:5173) to start planning!

## ğŸ”Œ API Endpoints

| Method | Path | Description | Access |
|--------|------|-------------|--------|
| **Auth** | | | |
| `POST` | `/auth/register` | Register new user | Public |
| `POST` | `/auth/login` | Login & get JWT | Public |
| `GET` | `/auth/me` | Get current user info | Auth |
| **Sessions** | | | |
| `GET` | `/sessions` | List all user plans | Auth |
| `POST` | `/session` | Create new plan/session | Auth |
| `GET` | `/session/{id}` | Get plan details | Auth |
| **Chat** | | | |
| `POST` | `/chat` | Send message to agent | Auth |
| `GET` | `/session/{id}/history` | Get chat history | Auth |
| `GET` | `/session/{id}/versions` | Get plan version history | Auth |

## ğŸ› ï¸ Tech Stack

- **AI/LLM:** Google Gemini 2.0 Flash, LangChain, LangGraph
- **Backend:** Python 3.10, FastAPI, Pydantic, PyJWT, Bcrypt
- **Database:** MongoDB (Motor async driver)
- **Frontend:** React 19, Vite, Lucide React
- **Styling:** Custom CSS Variables system ("Vibrant Pro" theme)

## How It Works

1. **Preprocess** â€” the user message is added to the session; preferences are extracted and context is compressed if needed.
2. **Generate** â€” the full conversation (or compressed summary + recent messages) is sent to Gemini with a structured-output system prompt. The LLM returns a JSON object with `thought`, `response_to_user`, `action`, `plan`, and `change_summary`.
3. **Postprocess** â€” the agent's response is recorded, and if a plan was created or updated, a new version is saved.

These three steps run as nodes in a **LangGraph** state graph.
